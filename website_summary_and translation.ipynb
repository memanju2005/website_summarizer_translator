{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install googletrans"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "eg4CEK5UGgnc",
        "outputId": "0b44d4b2-7a04-4e89-f76b-c726c834a16a"
      },
      "id": "eg4CEK5UGgnc",
      "execution_count": 76,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: googletrans in /usr/local/lib/python3.12/dist-packages (4.0.2)\n",
            "Requirement already satisfied: httpx>=0.27.2 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.27.2->googletrans) (0.28.1)\n",
            "Requirement already satisfied: anyio in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.10.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (2025.8.3)\n",
            "Requirement already satisfied: httpcore==1.* in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.0.9)\n",
            "Requirement already satisfied: idna in /usr/local/lib/python3.12/dist-packages (from httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (3.10)\n",
            "Requirement already satisfied: h11>=0.16 in /usr/local/lib/python3.12/dist-packages (from httpcore==1.*->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (0.16.0)\n",
            "Requirement already satisfied: h2<5,>=3 in /usr/local/lib/python3.12/dist-packages (from httpx[http2]>=0.27.2->googletrans) (4.2.0)\n",
            "Requirement already satisfied: hyperframe<7,>=6.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (6.1.0)\n",
            "Requirement already satisfied: hpack<5,>=4.1 in /usr/local/lib/python3.12/dist-packages (from h2<5,>=3->httpx[http2]>=0.27.2->googletrans) (4.1.0)\n",
            "Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (1.3.1)\n",
            "Requirement already satisfied: typing_extensions>=4.5 in /usr/local/lib/python3.12/dist-packages (from anyio->httpx>=0.27.2->httpx[http2]>=0.27.2->googletrans) (4.14.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4e2a9393-7767-488e-a8bf-27c12dca35bd",
        "outputId": "1ed49cdd-54d7-490d-859b-435f0c355091"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "done\n"
          ]
        }
      ],
      "source": [
        "# imports\n",
        "\n",
        "import os\n",
        "import requests\n",
        "from dotenv import load_dotenv\n",
        "from bs4 import BeautifulSoup\n",
        "from IPython.display import Markdown, display\n",
        "from openai import OpenAI\n",
        "print(\"done\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7b87cadb-d513-4303-baee-a37b6f938e4d",
        "outputId": "e7f902ce-7a41-4199-971d-acb077a3a8d3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "API key found and looks good so far!\n"
          ]
        }
      ],
      "source": [
        "# Load environment variables in a file called .env\n",
        "\n",
        "load_dotenv(override=True)\n",
        "api_key = os.getenv('OPENAI_API_KEY')\n",
        "#aiml_key = os.getenv('AIML_API_KEY')\n",
        "\n",
        "# Check the key\n",
        "\n",
        "if not api_key:\n",
        "    print(\"No API key was found \")\n",
        "elif not api_key.startswith(\"sk-proj-\"):\n",
        "    print(\"An API key was found, but it doesn't start sk-proj-; please check you're using the right key \")\n",
        "elif api_key.strip() != api_key:\n",
        "    print(\"An API key was found, but it looks like it might have space or tab characters at the start or end - please remove them - \")\n",
        "else:\n",
        "    print(\"API key found and looks good so far!\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "id": "019974d9-f3ad-4a8a-b5f9-0a3719aea2d3",
      "metadata": {
        "id": "019974d9-f3ad-4a8a-b5f9-0a3719aea2d3"
      },
      "outputs": [],
      "source": [
        "openai = OpenAI()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "id": "c5e793b2-6775-426a-a139-4848291d0463",
      "metadata": {
        "id": "c5e793b2-6775-426a-a139-4848291d0463"
      },
      "outputs": [],
      "source": [
        "# A class to represent a Webpage\n",
        "\n",
        "\n",
        "# Some websites need you to use proper headers when fetching them:\n",
        "headers = {\n",
        " \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/117.0.0.0 Safari/537.36\"\n",
        "}\n",
        "\n",
        "class Website:\n",
        "\n",
        "    def __init__(self, url):\n",
        "        \"\"\"\n",
        "        Create this Website object from the given url using the BeautifulSoup library\n",
        "        \"\"\"\n",
        "        self.url = url\n",
        "        response = requests.get(url, headers=headers)\n",
        "        soup = BeautifulSoup(response.content, 'html.parser')\n",
        "        self.title = soup.title.string if soup.title else \"No title found\"\n",
        "        for irrelevant in soup.body([\"script\", \"style\", \"img\", \"input\"]):\n",
        "            irrelevant.decompose()\n",
        "        self.text = soup.body.get_text(separator=\"\\n\", strip=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2ef960cf-6dc2-4cda-afb3-b38be12f4c97",
        "outputId": "4ffed3ee-5bcd-4066-92fb-d93233a89e68"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "paste the website link herehttps://huggingface.co/\n",
            "Hugging Face ‚Äì The AI community building the future.\n",
            "Hugging Face\n",
            "Models\n",
            "Datasets\n",
            "Spaces\n",
            "Community\n",
            "Docs\n",
            "Enterprise\n",
            "Pricing\n",
            "Log In\n",
            "Sign Up\n",
            "The AI community building the future.\n",
            "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
            "Explore AI Apps\n",
            "or\n",
            "Browse 1M+ models\n",
            "Trending on\n",
            "this week\n",
            "Models\n",
            "Qwen/Qwen-Image-Edit\n",
            "Updated\n",
            "3 days ago\n",
            "‚Ä¢\n",
            "16.8k\n",
            "‚Ä¢\n",
            "905\n",
            "deepseek-ai/DeepSeek-V3.1-Base\n",
            "Updated\n",
            "about 4 hours ago\n",
            "‚Ä¢\n",
            "5.68k\n",
            "‚Ä¢\n",
            "757\n",
            "google/gemma-3-270m\n",
            "Updated\n",
            "7 days ago\n",
            "‚Ä¢\n",
            "49.1k\n",
            "‚Ä¢\n",
            "538\n",
            "tencent/Hunyuan-GameCraft-1.0\n",
            "Updated\n",
            "2 days ago\n",
            "‚Ä¢\n",
            "74\n",
            "‚Ä¢\n",
            "437\n",
            "google/gemma-3-270m-it\n",
            "Updated\n",
            "7 days ago\n",
            "‚Ä¢\n",
            "67.9k\n",
            "‚Ä¢\n",
            "310\n",
            "Browse 1M+ models\n",
            "Spaces\n",
            "Running\n",
            "12.1k\n",
            "12.1k\n",
            "DeepSite v2\n",
            "üê≥\n",
            "Generate any application with DeepSeek\n",
            "Running\n",
            "on\n",
            "Zero\n",
            "200\n",
            "200\n",
            "Qwen Image Edit\n",
            "‚úí\n",
            "Edit images based on user instructions\n",
            "Running\n",
            "on\n",
            "Zero\n",
            "MCP\n",
            "260\n",
            "260\n",
            "Wan2.2 14B Fast\n",
            "üé•\n",
            "generate a video from an image with a text prompt\n",
            "Running\n",
            "on\n",
            "Zero\n",
            "691\n",
            "691\n",
            "Qwen Image\n",
            "üñº\n",
            "Generate images from text prompts\n",
            "Running\n",
            "on\n",
            "Zero\n",
            "146\n",
            "146\n",
            "Ovis2.5 9B\n",
            "üìä\n",
            "High-accuracy vision & reasoning for complex tasks\n",
            "Browse 400k+ applications\n",
            "Datasets\n",
            "fka/awesome-chatgpt-prompts\n",
            "Updated\n",
            "Jan 6\n",
            "‚Ä¢\n",
            "37.1k\n",
            "‚Ä¢\n",
            "8.79k\n",
            "nvidia/Granary\n",
            "Updated\n",
            "7 days ago\n",
            "‚Ä¢\n",
            "9.67k\n",
            "‚Ä¢\n",
            "97\n",
            "nvidia/Llama-Nemotron-VLM-Dataset-v1\n",
            "Updated\n",
            "2 days ago\n",
            "‚Ä¢\n",
            "2.97k\n",
            "‚Ä¢\n",
            "109\n",
            "allenai/WildChat-4.8M\n",
            "Updated\n",
            "10 days ago\n",
            "‚Ä¢\n",
            "2.68k\n",
            "‚Ä¢\n",
            "85\n",
            "FreedomIntelligence/medical-o1-reasoning-SFT\n",
            "Updated\n",
            "Apr 22\n",
            "‚Ä¢\n",
            "14.2k\n",
            "‚Ä¢\n",
            "843\n",
            "Browse 250k+ datasets\n",
            "The Home of Machine Learning\n",
            "Create, discover and collaborate on ML better.\n",
            "The collaboration platform\n",
            "Host and collaborate on unlimited public models, datasets and applications.\n",
            "Move faster\n",
            "With the HF Open source stack.\n",
            "Explore all modalities\n",
            "Text, image, video, audio or even 3D.\n",
            "Build your portfolio\n",
            "Share your work with the world and build your ML profile.\n",
            "Sign Up\n",
            "Accelerate your ML\n",
            "We provide paid Compute and Enterprise solutions.\n",
            "Compute\n",
            "Deploy on optimized\n",
            "Inference Endpoints\n",
            "or update your\n",
            "Spaces applications\n",
            "to a GPU in a few clicks.\n",
            "View pricing\n",
            "Starting at $0.60/hour for GPU\n",
            "Team & Enterprise\n",
            "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
            "\t\t\tdedicated support.\n",
            "Getting started\n",
            "Starting at $20/user/month\n",
            "Single Sign-On\n",
            "Regions\n",
            "Priority Support\n",
            "Audit Logs\n",
            "Resource Groups\n",
            "Private Datasets Viewer\n",
            "More than 50,000 organizations are using Hugging Face\n",
            "Ai2\n",
            "Enterprise\n",
            "non-profit\n",
            "‚Ä¢\n",
            "783 models\n",
            "‚Ä¢\n",
            "3.89k followers\n",
            "AI at Meta\n",
            "Enterprise\n",
            "company\n",
            "‚Ä¢\n",
            "2.22k models\n",
            "‚Ä¢\n",
            "7.36k followers\n",
            "Amazon\n",
            "company\n",
            "‚Ä¢\n",
            "20 models\n",
            "‚Ä¢\n",
            "3.37k followers\n",
            "Google\n",
            "Enterprise\n",
            "company\n",
            "‚Ä¢\n",
            "1.04k models\n",
            "‚Ä¢\n",
            "25.4k followers\n",
            "Intel\n",
            "company\n",
            "‚Ä¢\n",
            "239 models\n",
            "‚Ä¢\n",
            "2.91k followers\n",
            "Microsoft\n",
            "company\n",
            "‚Ä¢\n",
            "419 models\n",
            "‚Ä¢\n",
            "14.3k followers\n",
            "Grammarly\n",
            "Team\n",
            "company\n",
            "‚Ä¢\n",
            "11 models\n",
            "‚Ä¢\n",
            "173 followers\n",
            "Writer\n",
            "Enterprise\n",
            "company\n",
            "‚Ä¢\n",
            "21 models\n",
            "‚Ä¢\n",
            "322 followers\n",
            "Our Open Source\n",
            "We are building the foundation of ML tooling with the community.\n",
            "Transformers\n",
            "148,592\n",
            "State-of-the-art AI models for PyTorch\n",
            "Diffusers\n",
            "30,408\n",
            "State-of-the-art Diffusion models in PyTorch\n",
            "Safetensors\n",
            "3,407\n",
            "Safe way to store/distribute neural network weights\n",
            "Hub Python Library\n",
            "2,857\n",
            "Python client to interact with the Hugging Face Hub\n",
            "Tokenizers\n",
            "10,008\n",
            "Fast tokenizers optimized for research & production\n",
            "TRL\n",
            "15,188\n",
            "Train transformers LMs with reinforcement learning\n",
            "Transformers.js\n",
            "14,381\n",
            "State-of-the-art ML running directly in your browser\n",
            "smolagents\n",
            "22,264\n",
            "Smol library to build great agents in Python\n",
            "PEFT\n",
            "19,362\n",
            "Parameter-efficient finetuning for large language models\n",
            "Datasets\n",
            "20,532\n",
            "Access & share datasets for any ML tasks\n",
            "Text Generation Inference\n",
            "10,436\n",
            "Serve language models with TGI optimized toolkit\n",
            "Accelerate\n",
            "9,056\n",
            "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
            "System theme\n",
            "Website\n",
            "Models\n",
            "Datasets\n",
            "Spaces\n",
            "Changelog\n",
            "Inference Endpoints\n",
            "HuggingChat\n",
            "Company\n",
            "About\n",
            "Brand assets\n",
            "Terms of service\n",
            "Privacy\n",
            "Jobs\n",
            "Press\n",
            "Resources\n",
            "Learn\n",
            "Documentation\n",
            "Blog\n",
            "Forum\n",
            "Service Status\n",
            "Social\n",
            "GitHub\n",
            "Twitter\n",
            "LinkedIn\n",
            "Discord\n"
          ]
        }
      ],
      "source": [
        "# Let's try one out.\n",
        "link=input(\"paste the website link here\")\n",
        "site = Website(link)\n",
        "print(site.title)\n",
        "print(site.text)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6a478a0c-2c53-48ff-869c-4d08199931e1",
      "metadata": {
        "id": "6a478a0c-2c53-48ff-869c-4d08199931e1"
      },
      "source": [
        "## Types of prompts\n",
        "\n",
        "\n",
        "\n",
        "Models like GPT4o have been trained to receive instructions in a particular way.\n",
        "\n",
        "They expect to receive:\n",
        "\n",
        "**A system prompt** that tells them what task they are performing and what tone they should use\n",
        "\n",
        "**A user prompt** -- the conversation starter that they should reply to"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abdb8417-c5dc-44bc-9bee-2e059d162699",
        "outputId": "89cee949-804b-4203-fb00-07aed01c2e9a"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "You are looking at a website titled Hugging Face ‚Äì The AI community building the future.\n",
            "The contents of this website is as follows; please provide a  summary of this website in markdown. If it includes news or announcements, then summarize these too.\n",
            "\n",
            "Hugging Face\n",
            "Models\n",
            "Datasets\n",
            "Spaces\n",
            "Community\n",
            "Docs\n",
            "Enterprise\n",
            "Pricing\n",
            "Log In\n",
            "Sign Up\n",
            "The AI community building the future.\n",
            "The platform where the machine learning community collaborates on models, datasets, and applications.\n",
            "Explore AI Apps\n",
            "or\n",
            "Browse 1M+ models\n",
            "Trending on\n",
            "this week\n",
            "Models\n",
            "Qwen/Qwen-Image-Edit\n",
            "Updated\n",
            "3 days ago\n",
            "‚Ä¢\n",
            "16.8k\n",
            "‚Ä¢\n",
            "905\n",
            "deepseek-ai/DeepSeek-V3.1-Base\n",
            "Updated\n",
            "about 4 hours ago\n",
            "‚Ä¢\n",
            "5.68k\n",
            "‚Ä¢\n",
            "757\n",
            "google/gemma-3-270m\n",
            "Updated\n",
            "7 days ago\n",
            "‚Ä¢\n",
            "49.1k\n",
            "‚Ä¢\n",
            "538\n",
            "tencent/Hunyuan-GameCraft-1.0\n",
            "Updated\n",
            "2 days ago\n",
            "‚Ä¢\n",
            "74\n",
            "‚Ä¢\n",
            "437\n",
            "google/gemma-3-270m-it\n",
            "Updated\n",
            "7 days ago\n",
            "‚Ä¢\n",
            "67.9k\n",
            "‚Ä¢\n",
            "310\n",
            "Browse 1M+ models\n",
            "Spaces\n",
            "Running\n",
            "12.1k\n",
            "12.1k\n",
            "DeepSite v2\n",
            "üê≥\n",
            "Generate any application with DeepSeek\n",
            "Running\n",
            "on\n",
            "Zero\n",
            "200\n",
            "200\n",
            "Qwen Image Edit\n",
            "‚úí\n",
            "Edit images based on user instructions\n",
            "Running\n",
            "on\n",
            "Zero\n",
            "MCP\n",
            "260\n",
            "260\n",
            "Wan2.2 14B Fast\n",
            "üé•\n",
            "generate a video from an image with a text prompt\n",
            "Running\n",
            "on\n",
            "Zero\n",
            "691\n",
            "691\n",
            "Qwen Image\n",
            "üñº\n",
            "Generate images from text prompts\n",
            "Running\n",
            "on\n",
            "Zero\n",
            "146\n",
            "146\n",
            "Ovis2.5 9B\n",
            "üìä\n",
            "High-accuracy vision & reasoning for complex tasks\n",
            "Browse 400k+ applications\n",
            "Datasets\n",
            "fka/awesome-chatgpt-prompts\n",
            "Updated\n",
            "Jan 6\n",
            "‚Ä¢\n",
            "37.1k\n",
            "‚Ä¢\n",
            "8.79k\n",
            "nvidia/Granary\n",
            "Updated\n",
            "7 days ago\n",
            "‚Ä¢\n",
            "9.67k\n",
            "‚Ä¢\n",
            "97\n",
            "nvidia/Llama-Nemotron-VLM-Dataset-v1\n",
            "Updated\n",
            "2 days ago\n",
            "‚Ä¢\n",
            "2.97k\n",
            "‚Ä¢\n",
            "109\n",
            "allenai/WildChat-4.8M\n",
            "Updated\n",
            "10 days ago\n",
            "‚Ä¢\n",
            "2.68k\n",
            "‚Ä¢\n",
            "85\n",
            "FreedomIntelligence/medical-o1-reasoning-SFT\n",
            "Updated\n",
            "Apr 22\n",
            "‚Ä¢\n",
            "14.2k\n",
            "‚Ä¢\n",
            "843\n",
            "Browse 250k+ datasets\n",
            "The Home of Machine Learning\n",
            "Create, discover and collaborate on ML better.\n",
            "The collaboration platform\n",
            "Host and collaborate on unlimited public models, datasets and applications.\n",
            "Move faster\n",
            "With the HF Open source stack.\n",
            "Explore all modalities\n",
            "Text, image, video, audio or even 3D.\n",
            "Build your portfolio\n",
            "Share your work with the world and build your ML profile.\n",
            "Sign Up\n",
            "Accelerate your ML\n",
            "We provide paid Compute and Enterprise solutions.\n",
            "Compute\n",
            "Deploy on optimized\n",
            "Inference Endpoints\n",
            "or update your\n",
            "Spaces applications\n",
            "to a GPU in a few clicks.\n",
            "View pricing\n",
            "Starting at $0.60/hour for GPU\n",
            "Team & Enterprise\n",
            "Give your team the most advanced platform to build AI with enterprise-grade security, access controls and\n",
            "\t\t\tdedicated support.\n",
            "Getting started\n",
            "Starting at $20/user/month\n",
            "Single Sign-On\n",
            "Regions\n",
            "Priority Support\n",
            "Audit Logs\n",
            "Resource Groups\n",
            "Private Datasets Viewer\n",
            "More than 50,000 organizations are using Hugging Face\n",
            "Ai2\n",
            "Enterprise\n",
            "non-profit\n",
            "‚Ä¢\n",
            "783 models\n",
            "‚Ä¢\n",
            "3.89k followers\n",
            "AI at Meta\n",
            "Enterprise\n",
            "company\n",
            "‚Ä¢\n",
            "2.22k models\n",
            "‚Ä¢\n",
            "7.36k followers\n",
            "Amazon\n",
            "company\n",
            "‚Ä¢\n",
            "20 models\n",
            "‚Ä¢\n",
            "3.37k followers\n",
            "Google\n",
            "Enterprise\n",
            "company\n",
            "‚Ä¢\n",
            "1.04k models\n",
            "‚Ä¢\n",
            "25.4k followers\n",
            "Intel\n",
            "company\n",
            "‚Ä¢\n",
            "239 models\n",
            "‚Ä¢\n",
            "2.91k followers\n",
            "Microsoft\n",
            "company\n",
            "‚Ä¢\n",
            "419 models\n",
            "‚Ä¢\n",
            "14.3k followers\n",
            "Grammarly\n",
            "Team\n",
            "company\n",
            "‚Ä¢\n",
            "11 models\n",
            "‚Ä¢\n",
            "173 followers\n",
            "Writer\n",
            "Enterprise\n",
            "company\n",
            "‚Ä¢\n",
            "21 models\n",
            "‚Ä¢\n",
            "322 followers\n",
            "Our Open Source\n",
            "We are building the foundation of ML tooling with the community.\n",
            "Transformers\n",
            "148,592\n",
            "State-of-the-art AI models for PyTorch\n",
            "Diffusers\n",
            "30,408\n",
            "State-of-the-art Diffusion models in PyTorch\n",
            "Safetensors\n",
            "3,407\n",
            "Safe way to store/distribute neural network weights\n",
            "Hub Python Library\n",
            "2,857\n",
            "Python client to interact with the Hugging Face Hub\n",
            "Tokenizers\n",
            "10,008\n",
            "Fast tokenizers optimized for research & production\n",
            "TRL\n",
            "15,188\n",
            "Train transformers LMs with reinforcement learning\n",
            "Transformers.js\n",
            "14,381\n",
            "State-of-the-art ML running directly in your browser\n",
            "smolagents\n",
            "22,264\n",
            "Smol library to build great agents in Python\n",
            "PEFT\n",
            "19,362\n",
            "Parameter-efficient finetuning for large language models\n",
            "Datasets\n",
            "20,532\n",
            "Access & share datasets for any ML tasks\n",
            "Text Generation Inference\n",
            "10,436\n",
            "Serve language models with TGI optimized toolkit\n",
            "Accelerate\n",
            "9,056\n",
            "Train PyTorch models with multi-GPU, TPU, mixed precision\n",
            "System theme\n",
            "Website\n",
            "Models\n",
            "Datasets\n",
            "Spaces\n",
            "Changelog\n",
            "Inference Endpoints\n",
            "HuggingChat\n",
            "Company\n",
            "About\n",
            "Brand assets\n",
            "Terms of service\n",
            "Privacy\n",
            "Jobs\n",
            "Press\n",
            "Resources\n",
            "Learn\n",
            "Documentation\n",
            "Blog\n",
            "Forum\n",
            "Service Status\n",
            "Social\n",
            "GitHub\n",
            "Twitter\n",
            "LinkedIn\n",
            "Discord\n"
          ]
        }
      ],
      "source": [
        "# Define our system prompt -\n",
        "\n",
        "system_prompt = '''\n",
        "You are an assistant that analyzes the content of a website and provides a concise, user-friendly summary.\n",
        "\n",
        "Guidelines:\n",
        "\n",
        "Focus only on the main content of the webpage.\n",
        "\n",
        "Ignore navigation elements, menus, headers, footers, and repeated boilerplate text.\n",
        "\n",
        "Present the summary in Markdown format for readability.\n",
        "\n",
        "Keep the summary short and clear, highlighting the key information or purpose of the page.\n",
        "\n",
        "If the page has multiple main sections, provide a brief bullet-point breakdown.\n",
        "\n",
        "Do not include promotional or irrelevant filler text unless it contributes to the main content.'''\n",
        "# A function that writes a User Prompt that asks for summaries of websites:\n",
        "\n",
        "def user_prompt_for(website):\n",
        "    user_prompt = f\"You are looking at a website titled {website.title}\"\n",
        "    user_prompt += \"\\nThe contents of this website is as follows; \\\n",
        "please provide a  summary of this website in markdown. \\\n",
        "If it includes news or announcements, then summarize these too.\\n\\n\"\n",
        "    user_prompt += website.text\n",
        "    return user_prompt\n",
        "print(user_prompt_for(site))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d06e8d78-ce4c-4b05-aa8e-17050c82bb47",
      "metadata": {
        "id": "d06e8d78-ce4c-4b05-aa8e-17050c82bb47"
      },
      "source": [
        "## And now let's build useful messages for GPT-4o-mini, using a function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0134dfa4-8299-48b5-b444-f2a8c3403c88",
        "outputId": "2ee07590-f28d-4215-c9b7-3867050a868f"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[{'role': 'system',\n",
              "  'content': '\\nYou are an assistant that analyzes the content of a website and provides a concise, user-friendly summary.\\n\\nGuidelines:\\n\\nFocus only on the main content of the webpage.\\n\\nIgnore navigation elements, menus, headers, footers, and repeated boilerplate text.\\n\\nPresent the summary in Markdown format for readability.\\n\\nKeep the summary short and clear, highlighting the key information or purpose of the page.\\n\\nIf the page has multiple main sections, provide a brief bullet-point breakdown.\\n\\nDo not include promotional or irrelevant filler text unless it contributes to the main content.'},\n",
              " {'role': 'user',\n",
              "  'content': 'You are looking at a website titled Hugging Face ‚Äì The AI community building the future.\\nThe contents of this website is as follows; please provide a  summary of this website in markdown. If it includes news or announcements, then summarize these too.\\n\\nHugging Face\\nModels\\nDatasets\\nSpaces\\nCommunity\\nDocs\\nEnterprise\\nPricing\\nLog In\\nSign Up\\nThe AI community building the future.\\nThe platform where the machine learning community collaborates on models, datasets, and applications.\\nExplore AI Apps\\nor\\nBrowse 1M+ models\\nTrending on\\nthis week\\nModels\\nQwen/Qwen-Image-Edit\\nUpdated\\n3 days ago\\n‚Ä¢\\n16.8k\\n‚Ä¢\\n905\\ndeepseek-ai/DeepSeek-V3.1-Base\\nUpdated\\nabout 4 hours ago\\n‚Ä¢\\n5.68k\\n‚Ä¢\\n757\\ngoogle/gemma-3-270m\\nUpdated\\n7 days ago\\n‚Ä¢\\n49.1k\\n‚Ä¢\\n538\\ntencent/Hunyuan-GameCraft-1.0\\nUpdated\\n2 days ago\\n‚Ä¢\\n74\\n‚Ä¢\\n437\\ngoogle/gemma-3-270m-it\\nUpdated\\n7 days ago\\n‚Ä¢\\n67.9k\\n‚Ä¢\\n310\\nBrowse 1M+ models\\nSpaces\\nRunning\\n12.1k\\n12.1k\\nDeepSite v2\\nüê≥\\nGenerate any application with DeepSeek\\nRunning\\non\\nZero\\n200\\n200\\nQwen Image Edit\\n‚úí\\nEdit images based on user instructions\\nRunning\\non\\nZero\\nMCP\\n260\\n260\\nWan2.2 14B Fast\\nüé•\\ngenerate a video from an image with a text prompt\\nRunning\\non\\nZero\\n691\\n691\\nQwen Image\\nüñº\\nGenerate images from text prompts\\nRunning\\non\\nZero\\n146\\n146\\nOvis2.5 9B\\nüìä\\nHigh-accuracy vision & reasoning for complex tasks\\nBrowse 400k+ applications\\nDatasets\\nfka/awesome-chatgpt-prompts\\nUpdated\\nJan 6\\n‚Ä¢\\n37.1k\\n‚Ä¢\\n8.79k\\nnvidia/Granary\\nUpdated\\n7 days ago\\n‚Ä¢\\n9.67k\\n‚Ä¢\\n97\\nnvidia/Llama-Nemotron-VLM-Dataset-v1\\nUpdated\\n2 days ago\\n‚Ä¢\\n2.97k\\n‚Ä¢\\n109\\nallenai/WildChat-4.8M\\nUpdated\\n10 days ago\\n‚Ä¢\\n2.68k\\n‚Ä¢\\n85\\nFreedomIntelligence/medical-o1-reasoning-SFT\\nUpdated\\nApr 22\\n‚Ä¢\\n14.2k\\n‚Ä¢\\n843\\nBrowse 250k+ datasets\\nThe Home of Machine Learning\\nCreate, discover and collaborate on ML better.\\nThe collaboration platform\\nHost and collaborate on unlimited public models, datasets and applications.\\nMove faster\\nWith the HF Open source stack.\\nExplore all modalities\\nText, image, video, audio or even 3D.\\nBuild your portfolio\\nShare your work with the world and build your ML profile.\\nSign Up\\nAccelerate your ML\\nWe provide paid Compute and Enterprise solutions.\\nCompute\\nDeploy on optimized\\nInference Endpoints\\nor update your\\nSpaces applications\\nto a GPU in a few clicks.\\nView pricing\\nStarting at $0.60/hour for GPU\\nTeam & Enterprise\\nGive your team the most advanced platform to build AI with enterprise-grade security, access controls and\\n\\t\\t\\tdedicated support.\\nGetting started\\nStarting at $20/user/month\\nSingle Sign-On\\nRegions\\nPriority Support\\nAudit Logs\\nResource Groups\\nPrivate Datasets Viewer\\nMore than 50,000 organizations are using Hugging Face\\nAi2\\nEnterprise\\nnon-profit\\n‚Ä¢\\n783 models\\n‚Ä¢\\n3.89k followers\\nAI at Meta\\nEnterprise\\ncompany\\n‚Ä¢\\n2.22k models\\n‚Ä¢\\n7.36k followers\\nAmazon\\ncompany\\n‚Ä¢\\n20 models\\n‚Ä¢\\n3.37k followers\\nGoogle\\nEnterprise\\ncompany\\n‚Ä¢\\n1.04k models\\n‚Ä¢\\n25.4k followers\\nIntel\\ncompany\\n‚Ä¢\\n239 models\\n‚Ä¢\\n2.91k followers\\nMicrosoft\\ncompany\\n‚Ä¢\\n419 models\\n‚Ä¢\\n14.3k followers\\nGrammarly\\nTeam\\ncompany\\n‚Ä¢\\n11 models\\n‚Ä¢\\n173 followers\\nWriter\\nEnterprise\\ncompany\\n‚Ä¢\\n21 models\\n‚Ä¢\\n322 followers\\nOur Open Source\\nWe are building the foundation of ML tooling with the community.\\nTransformers\\n148,592\\nState-of-the-art AI models for PyTorch\\nDiffusers\\n30,408\\nState-of-the-art Diffusion models in PyTorch\\nSafetensors\\n3,407\\nSafe way to store/distribute neural network weights\\nHub Python Library\\n2,857\\nPython client to interact with the Hugging Face Hub\\nTokenizers\\n10,008\\nFast tokenizers optimized for research & production\\nTRL\\n15,188\\nTrain transformers LMs with reinforcement learning\\nTransformers.js\\n14,381\\nState-of-the-art ML running directly in your browser\\nsmolagents\\n22,264\\nSmol library to build great agents in Python\\nPEFT\\n19,362\\nParameter-efficient finetuning for large language models\\nDatasets\\n20,532\\nAccess & share datasets for any ML tasks\\nText Generation Inference\\n10,436\\nServe language models with TGI optimized toolkit\\nAccelerate\\n9,056\\nTrain PyTorch models with multi-GPU, TPU, mixed precision\\nSystem theme\\nWebsite\\nModels\\nDatasets\\nSpaces\\nChangelog\\nInference Endpoints\\nHuggingChat\\nCompany\\nAbout\\nBrand assets\\nTerms of service\\nPrivacy\\nJobs\\nPress\\nResources\\nLearn\\nDocumentation\\nBlog\\nForum\\nService Status\\nSocial\\nGitHub\\nTwitter\\nLinkedIn\\nDiscord'}]"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ],
      "source": [
        "# See how this function creates exactly the format above\n",
        "\n",
        "def messages_for(website):\n",
        "    return [\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": user_prompt_for(website)}\n",
        "    ]\n",
        "messages_for(site)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0",
      "metadata": {
        "id": "16f49d46-bf55-4c3e-928f-68fc0bf715b0"
      },
      "source": [
        "## Time to bring it together - the API for OpenAI is very simple!"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34",
      "metadata": {
        "id": "905b9919-aba7-45b5-ae65-81b3d1d78e34"
      },
      "outputs": [],
      "source": [
        "# And now: call the OpenAI API. You will get very familiar with this!\n",
        "\n",
        "def summarize(url):\n",
        "    website = Website(url)\n",
        "    response = openai.chat.completions.create(\n",
        "        model = \"gpt-4o-mini\",\n",
        "        messages = messages_for(website)\n",
        "    )\n",
        "    return response.choices[0].message.content\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
      "metadata": {
        "id": "3d926d59-450e-4609-92ba-2d6f244f1342",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 509
        },
        "outputId": "35c5e867-30f3-4993-ed08-1d98e2508256"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "paste the website link herehttps://huggingface.co/\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Hugging Face Summary\n\nHugging Face is a collaborative platform designed for the machine learning community to share, develop, and deploy models, datasets, and applications. It fosters collaboration and provides tools and resources for AI enthusiasts and professionals.\n\n## Key Features\n\n- **Models and Datasets**: Access over 1 million models and 250,000 datasets for various machine learning tasks.\n- **Spaces**: Run multiple applications like image editing, text generation, and video creation.\n- **Open Source Collaboration**: Contribute to foundational tools in machine learning, such as Transformers and Diffusers.\n- **Enterprise Solutions**: Offers paid computing resources, team collaboration features, and enterprise-grade support.\n\n## Recent Updates\n\n- **Trending Models**: \n  - **Qwen/Qwen-Image-Edit**: Updated 3 days ago.\n  - **DeepSeek-V3.1-Base**: Updated about 4 hours ago.\n  - **Google/gemma-3-270m**: Updated 7 days ago.\n  \n- **Spaces Running**: Include various applications like Qwen Image for generating images from text prompts and DeepSite for application generation.\n\n## Community Engagement\n\n- **Usage**: Over 50,000 organizations utilize Hugging Face, including major enterprises like Google and Microsoft.\n- **Collaboration**: Users can host public models and datasets, facilitating community participation and feedback.\n\nHugging Face serves as a comprehensive hub for machine learning development, emphasizing community collaboration and resource-sharing."
          },
          "metadata": {}
        }
      ],
      "source": [
        "url=input(\"paste the website link here\")\n",
        "summary = summarize(url)\n",
        "display(Markdown(summary))\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "\n",
        "# Your original markdown summary in English\n",
        "markdown_text = summary\n",
        "system_prompt='''\n",
        "Translate the following text from English to Hindi.\n",
        "Keep all Markdown formatting the same.\n",
        "Only translate the text, do not change symbols or structure.\n",
        "\n",
        "'''\n",
        "# Ask GPT-4o-mini to translate while keeping Markdown structure\n",
        "response = openai.chat.completions.create(\n",
        "    model=\"gpt-4o-mini\",\n",
        "    messages=[\n",
        "        {\"role\": \"system\", \"content\": system_prompt},\n",
        "        {\"role\": \"user\", \"content\": markdown_text}\n",
        "    ]\n",
        ")\n",
        "\n",
        "\n",
        "translated_markdown = response.choices[0].message.content\n",
        "print(translated_markdown)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9AztJ6CwGaxE",
        "outputId": "d5269498-d7e4-406c-a56c-f33fe48542a8"
      },
      "id": "9AztJ6CwGaxE",
      "execution_count": 86,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "# Hugging Face ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂\n",
            "\n",
            "Hugging Face ‡§è‡§ï ‡§∏‡§π‡§Ø‡•ã‡§ó‡•Ä ‡§Æ‡§Ç‡§ö ‡§π‡•à ‡§ú‡§ø‡§∏‡•á ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡•â‡§°‡§≤, ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§æ‡§ù‡§æ, ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§î‡§∞ ‡§§‡•à‡§®‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§Ø‡§π ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§µ‡§æ ‡§¶‡•á‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§è‡§Ü‡§à ‡§â‡§§‡•ç‡§∏‡§æ‡§π‡•Ä ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§î‡§∞ ‡§™‡•á‡§∂‡•á‡§µ‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§ï‡§∞‡§£ ‡§î‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\n",
            "\n",
            "## ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§µ‡§ø‡§∂‡•á‡§∑‡§§‡§æ‡§è‡§Å\n",
            "\n",
            "- **‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü**: ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è 1 ‡§Æ‡§ø‡§≤‡§ø‡§Ø‡§® ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ 250,000 ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§§‡§ï ‡§™‡§π‡•Å‡§Å‡§ö‡•á‡§Ç‡•§\n",
            "- **‡§∏‡•ç‡§™‡•á‡§∏**: ‡§õ‡§µ‡§ø ‡§∏‡§Ç‡§™‡§æ‡§¶‡§®, ‡§™‡§æ‡§† ‡§™‡•Ä‡§¢‡§º‡•Ä ‡§î‡§∞ ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ú‡•à‡§∏‡•Ä ‡§ï‡§à ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§ö‡§≤‡§æ‡§è‡§Å‡•§\n",
            "- **‡§ì‡§™‡§® ‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§∏‡§π‡§Ø‡•ã‡§ó**: ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§¨‡•Å‡§®‡§ø‡§Ø‡§æ‡§¶‡•Ä ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§ú‡•à‡§∏‡•á ‡§ï‡§ø Transformers ‡§î‡§∞ Diffusers ‡§Æ‡•á‡§Ç ‡§Ø‡•ã‡§ó‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§\n",
            "- **‡§â‡§¶‡•ç‡§Ø‡§Æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§®**: ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡§ø‡§è ‡§ó‡§è ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®, ‡§ü‡•Ä‡§Æ ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§è‡§Å, ‡§î‡§∞ ‡§â‡§¶‡•ç‡§Ø‡§Æ-‡§ó‡•ç‡§∞‡•á‡§° ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\n",
            "\n",
            "## ‡§π‡§æ‡§≤ ‡§ï‡•á ‡§Ö‡§™‡§°‡•á‡§ü\n",
            "\n",
            "- **‡§™‡•ç‡§∞‡§µ‡•É‡§§‡•ç‡§§ ‡§Æ‡•â‡§°‡§≤**: \n",
            "  - **Qwen/Qwen-Image-Edit**: 3 ‡§¶‡§ø‡§® ‡§™‡§π‡§≤‡•á ‡§Ö‡§™‡§°‡•á‡§ü ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ‡•§\n",
            "  - **DeepSeek-V3.1-Base**: ‡§≤‡§ó‡§≠‡§ó 4 ‡§ò‡§Ç‡§ü‡•á ‡§™‡§π‡§≤‡•á ‡§Ö‡§™‡§°‡•á‡§ü ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ‡•§\n",
            "  - **Google/gemma-3-270m**: 7 ‡§¶‡§ø‡§® ‡§™‡§π‡§≤‡•á ‡§Ö‡§™‡§°‡•á‡§ü ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ‡•§\n",
            "  \n",
            "- **‡§ö‡§æ‡§≤‡•Ç ‡§∏‡•ç‡§™‡•á‡§∏**: Qwen Image ‡§ú‡•à‡§∏‡•Ä ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§ú‡•ã ‡§™‡§æ‡§† ‡§∏‡§Ç‡§ï‡•á‡§§‡•ã‡§Ç ‡§∏‡•á ‡§ö‡§ø‡§§‡•ç‡§∞ ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§î‡§∞ DeepSite ‡§ú‡•ã ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•à‡•§\n",
            "\n",
            "## ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø ‡§∏‡§π‡§≠‡§æ‡§ó‡§ø‡§§‡§æ\n",
            "\n",
            "- **‡§â‡§™‡§Ø‡•ã‡§ó**: 50,000 ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡§Ç‡§ó‡§†‡§® Hugging Face ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç Google ‡§î‡§∞ Microsoft ‡§ú‡•à‡§∏‡•á ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§â‡§¶‡•ç‡§Ø‡§Æ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡§Ç‡•§\n",
            "- **‡§∏‡§π‡§Ø‡•ã‡§ó**: ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§ï‡•Ä ‡§Æ‡•á‡§ú‡§º‡§¨‡§æ‡§®‡•Ä ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø ‡§ï‡•Ä ‡§≠‡§æ‡§ó‡•Ä‡§¶‡§æ‡§∞‡•Ä ‡§î‡§∞ ‡§´‡•Ä‡§°‡§¨‡•à‡§ï ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§µ‡§æ ‡§Æ‡§ø‡§≤‡§§‡§æ ‡§π‡•à‡•§\n",
            "\n",
            "Hugging Face ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§∏‡•á‡§µ‡§æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§î‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§∞‡§®‡•á ‡§™‡§∞ ‡§ú‡•ã‡§∞ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "display(Markdown(translated_markdown))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 492
        },
        "id": "-EvHrY1PHYOs",
        "outputId": "fd7be6d2-ce32-4814-c246-77abe42d0c89"
      },
      "id": "-EvHrY1PHYOs",
      "execution_count": 87,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<IPython.core.display.Markdown object>"
            ],
            "text/markdown": "# Hugging Face ‡§∏‡§æ‡§∞‡§æ‡§Ç‡§∂\n\nHugging Face ‡§è‡§ï ‡§∏‡§π‡§Ø‡•ã‡§ó‡•Ä ‡§Æ‡§Ç‡§ö ‡§π‡•à ‡§ú‡§ø‡§∏‡•á ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø ‡§ï‡•á ‡§≤‡§ø‡§è ‡§Æ‡•â‡§°‡§≤, ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§î‡§∞ ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§∏‡§æ‡§ù‡§æ, ‡§µ‡§ø‡§ï‡§∏‡§ø‡§§ ‡§î‡§∞ ‡§§‡•à‡§®‡§æ‡§§ ‡§ï‡§∞‡§®‡•á ‡§ï‡•á ‡§≤‡§ø‡§è ‡§°‡§ø‡§ú‡§º‡§æ‡§á‡§® ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ ‡§π‡•à‡•§ ‡§Ø‡§π ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§µ‡§æ ‡§¶‡•á‡§§‡§æ ‡§π‡•à ‡§î‡§∞ ‡§è‡§Ü‡§à ‡§â‡§§‡•ç‡§∏‡§æ‡§π‡•Ä ‡§≤‡•ã‡§ó‡•ã‡§Ç ‡§î‡§∞ ‡§™‡•á‡§∂‡•á‡§µ‡§∞‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è ‡§â‡§™‡§ï‡§∞‡§£ ‡§î‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\n\n## ‡§Æ‡•Å‡§ñ‡•ç‡§Ø ‡§µ‡§ø‡§∂‡•á‡§∑‡§§‡§æ‡§è‡§Å\n\n- **‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü**: ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§ï‡§æ‡§∞‡•ç‡§Ø‡•ã‡§Ç ‡§ï‡•á ‡§≤‡§ø‡§è 1 ‡§Æ‡§ø‡§≤‡§ø‡§Ø‡§® ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ 250,000 ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§§‡§ï ‡§™‡§π‡•Å‡§Å‡§ö‡•á‡§Ç‡•§\n- **‡§∏‡•ç‡§™‡•á‡§∏**: ‡§õ‡§µ‡§ø ‡§∏‡§Ç‡§™‡§æ‡§¶‡§®, ‡§™‡§æ‡§† ‡§™‡•Ä‡§¢‡§º‡•Ä ‡§î‡§∞ ‡§µ‡•Ä‡§°‡§ø‡§Ø‡•ã ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ú‡•à‡§∏‡•Ä ‡§ï‡§à ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§ö‡§≤‡§æ‡§è‡§Å‡•§\n- **‡§ì‡§™‡§® ‡§∏‡•ã‡§∞‡•ç‡§∏ ‡§∏‡§π‡§Ø‡•ã‡§ó**: ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§Æ‡•á‡§Ç ‡§¨‡•Å‡§®‡§ø‡§Ø‡§æ‡§¶‡•Ä ‡§â‡§™‡§ï‡§∞‡§£‡•ã‡§Ç ‡§ú‡•à‡§∏‡•á ‡§ï‡§ø Transformers ‡§î‡§∞ Diffusers ‡§Æ‡•á‡§Ç ‡§Ø‡•ã‡§ó‡§¶‡§æ‡§® ‡§ï‡§∞‡•á‡§Ç‡•§\n- **‡§â‡§¶‡•ç‡§Ø‡§Æ ‡§∏‡§Æ‡§æ‡§ß‡§æ‡§®**: ‡§≠‡•Å‡§ó‡§§‡§æ‡§® ‡§ï‡§ø‡§è ‡§ó‡§è ‡§ï‡§Ç‡§™‡•ç‡§Ø‡•Ç‡§ü‡§ø‡§Ç‡§ó ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§®, ‡§ü‡•Ä‡§Æ ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§∏‡•Å‡§µ‡§ø‡§ß‡§æ‡§è‡§Å, ‡§î‡§∞ ‡§â‡§¶‡•ç‡§Ø‡§Æ-‡§ó‡•ç‡§∞‡•á‡§° ‡§∏‡§Æ‡§∞‡•ç‡§•‡§® ‡§™‡•ç‡§∞‡§¶‡§æ‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à‡•§\n\n## ‡§π‡§æ‡§≤ ‡§ï‡•á ‡§Ö‡§™‡§°‡•á‡§ü\n\n- **‡§™‡•ç‡§∞‡§µ‡•É‡§§‡•ç‡§§ ‡§Æ‡•â‡§°‡§≤**: \n  - **Qwen/Qwen-Image-Edit**: 3 ‡§¶‡§ø‡§® ‡§™‡§π‡§≤‡•á ‡§Ö‡§™‡§°‡•á‡§ü ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ‡•§\n  - **DeepSeek-V3.1-Base**: ‡§≤‡§ó‡§≠‡§ó 4 ‡§ò‡§Ç‡§ü‡•á ‡§™‡§π‡§≤‡•á ‡§Ö‡§™‡§°‡•á‡§ü ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ‡•§\n  - **Google/gemma-3-270m**: 7 ‡§¶‡§ø‡§® ‡§™‡§π‡§≤‡•á ‡§Ö‡§™‡§°‡•á‡§ü ‡§ï‡§ø‡§Ø‡§æ ‡§ó‡§Ø‡§æ‡•§\n  \n- **‡§ö‡§æ‡§≤‡•Ç ‡§∏‡•ç‡§™‡•á‡§∏**: Qwen Image ‡§ú‡•à‡§∏‡•Ä ‡§µ‡§ø‡§≠‡§ø‡§®‡•ç‡§® ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó‡•ã‡§Ç ‡§ï‡•ã ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§ú‡•ã ‡§™‡§æ‡§† ‡§∏‡§Ç‡§ï‡•á‡§§‡•ã‡§Ç ‡§∏‡•á ‡§ö‡§ø‡§§‡•ç‡§∞ ‡§â‡§§‡•ç‡§™‡§®‡•ç‡§® ‡§ï‡§∞‡§§‡§æ ‡§π‡•à ‡§î‡§∞ DeepSite ‡§ú‡•ã ‡§Ö‡§®‡•Å‡§™‡•ç‡§∞‡§Ø‡•ã‡§ó ‡§®‡§ø‡§∞‡•ç‡§Æ‡§æ‡§£ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§π‡•à‡•§\n\n## ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø ‡§∏‡§π‡§≠‡§æ‡§ó‡§ø‡§§‡§æ\n\n- **‡§â‡§™‡§Ø‡•ã‡§ó**: 50,000 ‡§∏‡•á ‡§Ö‡§ß‡§ø‡§ï ‡§∏‡§Ç‡§ó‡§†‡§® Hugging Face ‡§ï‡§æ ‡§â‡§™‡§Ø‡•ã‡§ó ‡§ï‡§∞ ‡§∞‡§π‡•á ‡§π‡•à‡§Ç, ‡§ú‡§ø‡§∏‡§Æ‡•á‡§Ç Google ‡§î‡§∞ Microsoft ‡§ú‡•à‡§∏‡•á ‡§™‡•ç‡§∞‡§Æ‡•Å‡§ñ ‡§â‡§¶‡•ç‡§Ø‡§Æ ‡§∂‡§æ‡§Æ‡§ø‡§≤ ‡§π‡•à‡§Ç‡•§\n- **‡§∏‡§π‡§Ø‡•ã‡§ó**: ‡§â‡§™‡§Ø‡•ã‡§ó‡§ï‡§∞‡•ç‡§§‡§æ ‡§∏‡§æ‡§∞‡•ç‡§µ‡§ú‡§®‡§ø‡§ï ‡§Æ‡•â‡§°‡§≤ ‡§î‡§∞ ‡§°‡•á‡§ü‡§æ‡§∏‡•á‡§ü ‡§ï‡•Ä ‡§Æ‡•á‡§ú‡§º‡§¨‡§æ‡§®‡•Ä ‡§ï‡§∞ ‡§∏‡§ï‡§§‡•á ‡§π‡•à‡§Ç, ‡§ú‡§ø‡§∏‡§∏‡•á ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø ‡§ï‡•Ä ‡§≠‡§æ‡§ó‡•Ä‡§¶‡§æ‡§∞‡•Ä ‡§î‡§∞ ‡§´‡•Ä‡§°‡§¨‡•à‡§ï ‡§ï‡•ã ‡§¨‡§¢‡§º‡§æ‡§µ‡§æ ‡§Æ‡§ø‡§≤‡§§‡§æ ‡§π‡•à‡•§\n\nHugging Face ‡§Æ‡§∂‡•Ä‡§® ‡§≤‡§∞‡•ç‡§®‡§ø‡§Ç‡§ó ‡§µ‡§ø‡§ï‡§æ‡§∏ ‡§ï‡•á ‡§≤‡§ø‡§è ‡§è‡§ï ‡§µ‡•ç‡§Ø‡§æ‡§™‡§ï ‡§ï‡•á‡§Ç‡§¶‡•ç‡§∞ ‡§ï‡•á ‡§∞‡•Ç‡§™ ‡§Æ‡•á‡§Ç ‡§∏‡•á‡§µ‡§æ ‡§ï‡§∞‡§§‡§æ ‡§π‡•à, ‡§ú‡•ã ‡§∏‡§Æ‡•Å‡§¶‡§æ‡§Ø ‡§∏‡§π‡§Ø‡•ã‡§ó ‡§î‡§∞ ‡§∏‡§Ç‡§∏‡§æ‡§ß‡§® ‡§∏‡§æ‡§ù‡§æ ‡§ï‡§∞‡§®‡•á ‡§™‡§∞ ‡§ú‡•ã‡§∞ ‡§¶‡•á‡§§‡§æ ‡§π‡•à‡•§"
          },
          "metadata": {}
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}